{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124fd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.expected_conditions import presence_of_element_located\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import time \n",
    "import string\n",
    "import os\n",
    "import nltk\n",
    "#from nltk.stem import WordNetLemmatize\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3f8d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.81M/6.81M [00:00<00:00, 38.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Assessing CHROME and opening page\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.google.com\")\n",
    "\n",
    "browser = driver\n",
    "url = \"https://www.google.com/maps/place/Christ+(Deemed+to+be+University)/@12.9364929,77.6025247,17z/data=!4m7!3m6!1s0x3bae15b277a93807:0x88518f37b39dabd0!8m2!3d12.9362362!4d77.6061888!9m1!1b1\"\n",
    "browser.get(url)\n",
    "response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968834cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last height: 556\n",
      "new height: 49\n",
      "cont\n",
      "last height: 49\n",
      "new height: 48\n",
      "cont\n",
      "last height: 48\n",
      "new height: 48\n"
     ]
    }
   ],
   "source": [
    "# scrolling to the end of the Reviews webpage on chrome to load all avaliable reviews\n",
    "\n",
    "i = 0\n",
    "\n",
    "SCROLL_PAUSE_TIME = 10\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "number = 0\n",
    "\n",
    "while True:\n",
    "    number = number+1\n",
    "\n",
    "    # Scroll down to bottom\n",
    "\n",
    "    ele = driver.find_element(By.XPATH,'//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "    driver.execute_script('arguments[0].scrollBy(0, 5000);', ele)\n",
    "\n",
    "    # Wait to load page\n",
    "\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    print(f'last height: {last_height}')\n",
    "\n",
    "    ele = driver.find_element(By.XPATH,'//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", ele)\n",
    "\n",
    "    print(f'new height: {new_height}')\n",
    "\n",
    "    if number == 5:\n",
    "        break\n",
    "\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "\n",
    "    print('cont')\n",
    "    last_height = new_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b30b6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing and extracting the elements from each review on the webpage \n",
    "\n",
    "reviews = []  \n",
    "time_ago = []\n",
    "ratings = []\n",
    "names = []\n",
    "    \n",
    "review = driver.find_elements(By.CLASS_NAME,\"wiI7pd\")\n",
    "\n",
    "for j in review:\n",
    "    p = str(j.text)\n",
    "    if p is not None: \n",
    "        reviews.append(p)\n",
    "    else:\n",
    "        s = 'no review'\n",
    "        reviews.append(s)\n",
    "    \n",
    "    \n",
    "time = driver.find_elements(By.CLASS_NAME,\"rsqaWe\")\n",
    "\n",
    "for k in time:\n",
    "    o = str(k.text)\n",
    "    time_ago.append(o)\n",
    "    \n",
    "\n",
    "rating = driver.find_elements(By.CLASS_NAME,'kvMYJc')\n",
    "\n",
    "for l in rating:\n",
    "    c = str((l.get_attribute(\"aria-label\")))\n",
    "    ratings.append(c)\n",
    "\n",
    "username = driver.find_elements(By.CLASS_NAME,\"d4r55\")   \n",
    "\n",
    "for m in username:\n",
    "    s = str(m.text)\n",
    "    names.append(s)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dd638a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148\n",
      "1140\n",
      "1140\n",
      "1140\n"
     ]
    }
   ],
   "source": [
    "#finding length\n",
    "print(len(reviews))\n",
    "print(len(time_ago))\n",
    "print(len(ratings))\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "430091c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1148"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.DataFrame(reviews)\n",
    "norev = reviews[ (reviews == 'no review') ].index\n",
    "norev.drop(norev)\n",
    "#names to Dataframe\n",
    "names = pd.DataFrame(names)\n",
    "len(norev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af89e8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the ratings to extract only the numbers ie \" 5 stars\" -> '5'\n",
    "\n",
    "split_rate =[]\n",
    "for r in range (len(ratings)):\n",
    "    b = ratings[r]\n",
    "    a = (b[1])\n",
    "    split_rate.append(a)\n",
    "\n",
    "split = pd.DataFrame(split_rate)\n",
    "len(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6241090",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# creating data frame with scraped values \u001b[39;00m\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m=\u001b[39mnames\n\u001b[1;32m----> 3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSERNAME\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m names\n\u001b[0;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREVIEWS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#data['RATINGS'] = split_rate\u001b[39;00m\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\core\\frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   3972\u001b[0m     is_list_like(value)\n\u001b[0;32m   3973\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[0;32m   3975\u001b[0m ):\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\core\\frame.py:4100\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4098\u001b[0m len_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(cols) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols)\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m len_cols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 4100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4102\u001b[0m \u001b[38;5;66;03m# align right-hand-side columns if self.columns\u001b[39;00m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;66;03m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n\u001b[0;32m   4104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   4105\u001b[0m     loc, (\u001b[38;5;28mslice\u001b[39m, Series, np\u001b[38;5;241m.\u001b[39mndarray, Index)\n\u001b[0;32m   4106\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# creating data frame with scraped values \n",
    "data=names\n",
    "data['USERNAME'] = names\n",
    "data['REVIEWS'] = reviews\n",
    "#data['RATINGS'] = split_rate\n",
    "data['RATINGS'] = split\n",
    "data['TIME AGO'] = time_ago\n",
    "\n",
    "data = data[['USERNAME','REVIEWS','RATINGS','TIME AGO']]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8613e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating csv file with dataframe\n",
    "#data.to_csv('Google_reviews_central.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e956bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>REVIEWS</th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>TIME AGO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARPIT SOOD</td>\n",
       "      <td>Recently went to Christ University for a Marke...</td>\n",
       "      <td></td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avik</td>\n",
       "      <td>This is a beautiful campus. There are many tre...</td>\n",
       "      <td></td>\n",
       "      <td>a month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sonakshi Massey</td>\n",
       "      <td>I was a part of the BBA program offered by the...</td>\n",
       "      <td></td>\n",
       "      <td>a day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jino narzary</td>\n",
       "      <td>Beautiful campus and really lovely atmosphere ...</td>\n",
       "      <td></td>\n",
       "      <td>a year ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senthilkumar N K</td>\n",
       "      <td>Christ University offers UG, PG, and Ph.D. pro...</td>\n",
       "      <td></td>\n",
       "      <td>8 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           USERNAME                                            REVIEWS  \\\n",
       "0        ARPIT SOOD  Recently went to Christ University for a Marke...   \n",
       "1              Avik  This is a beautiful campus. There are many tre...   \n",
       "2   Sonakshi Massey  I was a part of the BBA program offered by the...   \n",
       "3      jino narzary  Beautiful campus and really lovely atmosphere ...   \n",
       "4  Senthilkumar N K  Christ University offers UG, PG, and Ph.D. pro...   \n",
       "\n",
       "  RATINGS      TIME AGO  \n",
       "0          4 months ago  \n",
       "1           a month ago  \n",
       "2             a day ago  \n",
       "3            a year ago  \n",
       "4          8 months ago  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading created csv file\n",
    "df = pd.read_csv(\"Google_reviews_central.csv\")\n",
    "df.drop(columns = df.columns[0], axis = 1, inplace= True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6f1c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assign all the rating >3 as 1 else 0\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m=\u001b[39mdf[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRATINGS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOSITIVELY RATED\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRATINGS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m df\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\core\\arraylike.py:58\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__gt__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\core\\series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     73\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\new_anoconda\\lib\\site-packages\\pandas\\_libs\\ops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# cleaning dataset\n",
    "#Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "# Assign all the rating >3 as 1 else 0\n",
    "df=df[df['RATINGS']!=3]\n",
    "df['POSITIVELY RATED']= np.where(df['RATINGS']>3,1,0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354efe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the data\n",
    "clean = df.REVIEWS.values.tolist()\n",
    "import re\n",
    "clean=[re.sub(r\"@\\S+\", \"\",sent) for sent in clean]\n",
    "# Removing URL\n",
    "clean=[re.sub(\"http[s]?\\://\\S+\",\"\",sent) for sent in clean]\n",
    "#Removing hashtag (#…)\n",
    "clean=[re.sub(r\"#\\S+\", \"\",sent) for sent in clean]# removing #NLP\n",
    "# Removing Numbers \n",
    "clean=[re.sub(r\"[0-9]\", \"\",sent) for sent in clean]\n",
    "#Removing text in brackets ([…] or (…))\n",
    "clean=[re.sub(r\"(\\(.*\\))|(\\[.*\\])\", \"\",sent) for sent in clean] \n",
    "# Removing line or tab character (\\n, \\r, \\t..)\n",
    "clean=[re.sub(r\"\\n\", \"\",sent) for sent in clean] # removing \\n\n",
    "# Removing Punctuations\n",
    "clean= [re.sub(r'[^\\w\\s]', '',sent) for sent in clean]\n",
    "clean=[sent.lower() for sent in clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizing the contents to bring the words to their base form\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "post_lemma = []\n",
    "for i in range (len(clean)):\n",
    "    # Tokenize: Split the sentence into words\n",
    "    word_list = nltk.word_tokenize(clean[i])\n",
    "    # Lemmatize list of words and join\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    post_lemma.append(lemmatized_output)\n",
    "    \n",
    "post_lemma = pd.DataFrame(post_lemma)\n",
    "df['LEMMATIZED'] = post_lemma \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04512cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING NLTK TO REMOVE STOP WORDS\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['christ university','university','universities','bengaluru',\n",
    "                   'bangalore','hosur','rd','road','christite','christmas','decorations'\n",
    "                  'campus','education','knowledge','college','colleges','placements','ranked','deemed','central','block',\n",
    "                  'christ'])\n",
    "\n",
    "df['CLEAN REVIEWS'] = df['LEMMATIZED'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d5935",
   "metadata": {},
   "source": [
    "# VADER - NON-ML TECHINQUES (LEXICON BASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198728de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer #initiating VADER instance\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon') \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating score for each tweet in the dataframe/dataset\n",
    "\n",
    "i=0 \n",
    "\n",
    "compval1 = [ ]  \n",
    "\n",
    "while i<len(df):\n",
    "    \n",
    "    k = analyser.polarity_scores(df.iloc[i]['CLEAN REVIEWS'])\n",
    "    compval1.append(k['compound'])\n",
    "    \n",
    "    i = i+1\n",
    "    \n",
    "compval1 = np.array(compval1)\n",
    "\n",
    "len(compval1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VADER SCORE'] = compval1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228eeb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the vader score into 3 categories \n",
    "i = 0\n",
    "\n",
    "predicted_value = [ ] #empty series to hold our predicted values\n",
    "\n",
    "while(i<len(df)):\n",
    "    if ((df.iloc[i]['VADER SCORE'] >= 0.5)):\n",
    "        predicted_value.append('positive')\n",
    "        i = i+1\n",
    "    elif ((df.iloc[i]['VADER SCORE'] > 0) & (df.iloc[i]['VADER SCORE'] < 0.5)):\n",
    "        predicted_value.append('neutral')\n",
    "        i = i+1\n",
    "    elif ((df.iloc[i]['VADER SCORE'] <= 0)):\n",
    "        predicted_value.append('negative')\n",
    "        i = i+1\n",
    "        \n",
    "df['VADER SENTIMENT'] = predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485984db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78957bf6",
   "metadata": {},
   "source": [
    "# ML TECHINQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7426ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['CLEAN REVIEWS'], df['POSITIVELY RATED'], train_size=0.7,test_size=0.3,random_state=1)\n",
    "\n",
    "print('Training dataset first entry:\\n', X_train[0])\n",
    "print(\"\\nShape of Training Dataset\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer().fit(X_train)\n",
    "X_train_vectorized=vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22adf709",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4847e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model= Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', svm.SVC(C=1.0, kernel='linear', gamma='auto'))])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f74ae",
   "metadata": {},
   "source": [
    "# SDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Classifier\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f900944",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ff641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model= Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "            ('mnb', MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None))])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a346e1f",
   "metadata": {},
   "source": [
    "# PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the seaborn library\n",
    "import seaborn as sns\n",
    " \n",
    "# importings done to avoid warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1504dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting to know the spread of ratings\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x ='RATINGS', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting to compare number of positive, netural and negative reviews according to 'VADER'\n",
    "sns.countplot(x ='VADER SENTIMENT', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b82478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting to compare number of positive vs number of negative reviews according to 'RATINGS'\n",
    "sns.countplot(x ='POSITIVELY RATED', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting box plot to compare rating vs vader score\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize =(12, 8))\n",
    "sns.boxplot(x ='RATINGS', y ='VADER SCORE', data = df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
